% Encoding: UTF-8

@MastersThesis{,
  author   = {Goyal, Poonam},
  title    = {A comparative study of C, Java, C# and Jython},
  abstract = {Comparing programming languages is a common topic among programmers and software
developers. With the recent changes in programming standards and continual upgrades in
hardware design, many new programming languages are being developed, while existing
ones are currently going through several enhancements in terms of design and
implementation. In this research, we present a comparative study of four programming
languages, C, Java, C#, and Jython, with respect to the following criteria: memory
consumption, CPU utilization, and execution time. Each test was performed in a
distributed system using TCP sockets with 1, 2, 4 and 8 clients, and on a symmetric
multiprocessing system.},
  comment  = {Der Autor vergleicht die Implementierungen von vier verschiedenen Algorithmen in vier Programmiersprachen auf Performanz, Speicherverbrauch und Ausführungszeit in einem Client-Server Setup mit mehreren Clients. Der Autor kommt zum Ergebnis, dass eine Programmiersprache bestimmten Einfluss auf die Performanz und andere Laufzeit-Eigenschaften hat. 

Future Work: Vergleich auf verschiedenen Plattformen, z. B. Windows vs Linux.},
  keywords = {rank2},
  year     = {2014},
}

@Article{,
  author   = {Balasubramanian, Abhiram and Baranowski, Marek S. and Burtsev, Anton and Panda, Aurojit and Rakamari, Zvonimir and Ryzhyk, Leonid},
  title    = {System Programming in Rust: Beyond Safety},
  doi      = {10.1145/3139645.3139660},
  issn     = {0163-5980},
  issue    = {August 2017},
  number   = {1},
  url      = {https://doi.org/10.1145/3139645.3139660},
  volume   = {51},
  comment  = {Die Autoren schlagen Beispielimplementierungen für},
  keywords = {rank4},
  year     = {2017},
}

@InProceedings{,
  author    = {Levy, Amit and Campbell, Bradford and Ghena, Branden and Giffin, Daniel B. and Pannuto, Pat and Dutta, Prabal and Levis, Philip},
  title     = {Multiprogramming a 64kB Computer Safely and Efficiently},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  year      = {2017},
  isbn      = {9781450350853},
  pages     = {234-251},
  doi       = {10.1145/3132747.3132786},
  url       = {https://doi.org/10.1145/3132747.3132786},
  keywords  = {rank2},
}

@InProceedings{,
  author    = {Evans, Ana Nora and Campbell, Bradford and Soffa, Mary Lou},
  title     = {Is Rust Used Safely by Software Developers?},
  booktitle = {2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  year      = {2020},
  pages     = {246-257},
  abstract  = {Rust, an emerging programming language with explosive growth,
provides a robust type system that enables programmers to write
memory-safe and data-race free code. To allow access to a machine’s
hardware and to support low-level performance optimizations, a
second language, Unsafe Rust, is embedded in Rust. It contains
support for operations that are difficult to statically check, such
as C-style pointers for access to arbitrary memory locations and
mutable global variables. When a program uses these features, the
compiler is unable to statically guarantee the safety properties
Rust promotes. In this work, we perform a large-scale empirical
study to explore how software developers are using Unsafe Rust in
real-world Rust libraries and applications. Our results indicate that
software engineers use the keyword unsafe in less than 30% of Rust
libraries, but more than half cannot be entirely statically checked
by the Rust compiler because of Unsafe Rust hidden somewhere
in a library’s call chain. We conclude that although the use of the
keyword unsafe is limited, the propagation of unsafeness offers
a challenge to the claim of Rust as a memory-safe language. Furthermore, we recommend changes to the Rust compiler and to the
central Rust repository’s interface to help Rust software developers
be aware of when their Rust code is unsafe.},
  comment   = {Die Autoren untersuchen Open-Source Projekte, die in Rust geschrieben wurden und analysieren inwieweit die Entwickler der Projekte die unsicheren Features von Rust verwenden und die Sicherheiten des Compilers umgeben (unsafe code).
Das Paper zitiert auch mehrere andere Artikel, die auf die Sicherheiten von Rust eingehen und die Sprache mit C und C++ vergleichen.},
  keywords  = {rank5},
}

@InProceedings{Anderson2016,
  author    = {Anderson, Brian and Bergstrom, Lars and Goregaokar, Manish and Matthews, Josh and McAllister, Keegan and Moffitt, Jack and Sapin, Simon},
  booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
  title     = {Engineering the Servo Web Browser Engine Using Rust},
  doi       = {10.1145/2889160.2889229},
  isbn      = {9781450342056},
  pages     = {81-89},
  abstract  = {All modern web browsers --- Internet Explorer, Firefox, Chrome, Opera, and Safari --- have a core rendering engine written in C++. This language choice was made because it affords the systems programmer complete control of the underlying hardware features and memory in use, and it provides a transparent compilation model. Unfortunately, this language is complex (especially to new contributors!), challenging to write correct parallel code in, and highly susceptible to memory safety issues that potentially lead to security holes.Servo is a project started at Mozilla Research to build a new web browser engine that preserves the capabilities of these other browser engines but also both takes advantage of the recent trends in parallel hardware and is more memory-safe. We use a new language, Rust, that provides us a similar level of control of the underlying system to C++ but which statically prevents many memory safety issues and provides direct support for parallelism and concurrency.In this paper, we show how a language with an advanced type system can address many of the most common security issues and software engineering challenges in other browser engines, while still producing code that has the same performance and memory profile. This language is also quite accessible to new open source contributors and employees, even those without a background in C++ or systems programming. We also outline several pitfalls encountered along the way and describe some potential areas for future improvement.},
  keywords  = {rank5},
  year      = {2016},
}

@InProceedings{,
  author    = {Boos, Kevin and Zhong, Lin},
  title     = {Theseus: A State Spill-Free Operating System},
  booktitle = {Proceedings of the 9th Workshop on Programming Languages and Operating Systems},
  year      = {2017},
  isbn      = {9781450351539},
  pages     = {29-35},
  doi       = {10.1145/3144555.3144560},
  abstract  = {In prior work, we have shown that the underdiagnosed problem of state spill remains a barrier to realizing complex systems that are easy to maintain, evolve, and run reliably. This paper shares our early experience building Theseus from scratch, an OS with the guiding principle of eliminating state spill. Theseus takes inspiration from distributed systems to rethink state management, and leverages Rust language features for maximum safety, code reuse, and efficient isolation. We intend to demonstrate Theseus as a runtime composable OS, in which entities are easily interchangeable and can evolve independently without reconfiguring or rebooting.},
}

@Article{,
  author   = {Lin, Yi and Blackburn, Stephen M. and Hosking, Antony L. and Norrish, Michael},
  title    = {Rust as a Language for High Performance GC Implementation},
  journal  = {SIGPLAN Not.},
  year     = {2016},
  pages    = {89-98},
  issn     = {0362-1340},
  doi      = {10.1145/3241624.2926707},
  abstract = {High performance garbage collectors build upon performance-critical low-level code, typically exhibit multiple levels of concurrency, and are prone to subtle bugs. Implementing, debugging and maintaining such collectors can therefore be extremely challenging. The choice of implementation language is a crucial consideration when building a collector. Typically, the drive for performance and the need for efficient support of low-level memory operations leads to the use of low-level languages like C or C++, which offer little by way of safety and software engineering benefits. This risks undermining the robustness and flexibility of the collector design. Rust's ownership model, lifetime specification, and reference borrowing deliver safety guarantees through a powerful static checker with little runtime overhead. These features make Rust a compelling candidate for a collector implementation language, but they come with restrictions that threaten expressiveness and efficiency. We describe our experience implementing an Immix garbage collector in Rust and C. We discuss the benefits of Rust, the obstacles encountered, and how we overcame them. We show that our Immix implementation has almost identical performance on micro benchmarks, compared to its implementation in C, and outperforms the popular BDW collector on the gcbench micro benchmark. We find that Rust's safety features do not create significant barriers to implementing a high performance collector. Though memory managers are usually considered low-level, our high performance implementation relies on very little unsafe code, with the vast majority of the implementation benefiting from Rust's safety. We see our experience as a compelling proof-of-concept of Rust as an implementation language for high performance garbage collection.},
  comment  = {Der Artikel beschreibt die Vorteile und Nachteile von Rust gegenüber C.},
  keywords = {rank5},
}

@Article{,
  author = {Gens, David and Schmitt, Simon and Davi, Lucas and Sadeghi, Ahmad-Reza},
  title  = {K-Miner: Uncovering Memory Corruption in Linux},
  year   = {2018},
  doi    = {10.14722/ndss.2018.23326},
}

@InProceedings{,
  author    = {Szekeres, László and Payer, Mathias and Wei, Tao and Song, Dawn},
  title     = {SoK: Eternal War in Memory},
  booktitle = {2013 IEEE Symposium on Security and Privacy},
  year      = {2013},
  pages     = {48-26},
  doi       = {10.1109/SP.2013.13},
}

@InProceedings{,
  author    = {Qin, Boqin and Chen, Yilun and Yu, Zeming and Song, Linhai and Zhang, Yiying},
  title     = {Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs},
  booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
  year      = {2020},
  pages     = {763–779},
  doi       = {10.1145/3385412.3386036},
  abstract  = {Rust is a young programming language designed for systems software development. It aims to provide safety guarantees like high-level languages and performance efficiency like low-level languages. The core design of Rust is a set of strict safety rules enforced by compile-time checking. To support more low-level controls, Rust allows programmers to bypass these compiler checks to write unsafe code. It is important to understand what safety issues exist in real Rust programs and how Rust safety mechanisms impact programming practices. We performed the first empirical study of Rust by close, manual inspection of 850 unsafe code usages and 170 bugs in five open-source Rust projects, five widely-used Rust libraries, two online security databases, and the Rust standard library. Our study answers three important questions: how and why do programmers write unsafe code, what memory-safety issues real Rust programs have, and what concurrency bugs Rust programmers make. Our study reveals interesting real-world Rust program behaviors and new issues Rust programmers make. Based on our study results, we propose several directions of building Rust bug detectors and built two static bug detectors, both of which revealed previously unknown bugs.},
  keywords  = {rank5},
}

@Article{ARDITO2020100635,
  author   = {Luca Ardito and Luca Barbato and Marco Castelluccio and Riccardo Coppola and Calixte Denizet and Sylvestre Ledru and Michele Valsesia},
  title    = {rust-code-analysis: A Rust library to analyze and extract maintainability information from source codes},
  doi      = {https://doi.org/10.1016/j.softx.2020.100635},
  issn     = {2352-7110},
  pages    = {100635},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352711020303484},
  volume   = {12},
  abstract = {The literature proposes many software metrics for evaluating the source code non-functional properties, such as its complexity and maintainability. The literature also proposes several tools to compute those properties on source codes developed with many different software languages. However, the Rust language emergence has not been paired by the community’s effort in developing parsers and tools able to compute metrics for the Rust source code. Also, metrics tools often fall short in providing immediate means of comparing maintainability metrics between different algorithms or coding languages. We hence introduce rust-code-analysis, a Rust library that allows the extraction of a set of eleven maintainability metrics for ten different languages, including Rust. rust-code-analysis, through the Abstract Syntax Tree (AST) of a source file, allows the inspection of the code structure, analyzing source code metrics at different levels of granularity, and finding code syntax errors before compiling time. The tool also offers a command-line interface that allows exporting the results in different formats. The possibility of analyzing source codes written in different programming languages enables simple and systematic comparisons between the metrics produced from different empirical and large-scale analysis sources.},
  comment  = {Die Autoren präsentieren ein Tool, welches Code in verschiedenen Sprachen analysieren und verschiedene Metriken als Ergebnis zurück geben kann, auch für Rust (z. B. LOC, Code Complexity, usw.). 

Future Work: "For researchers in software engineering, the tool can be
used to either conduct empirical studies and compare maintainability properties between implementations of the same
algorithm in different languages or implement different algorithms in the same language."},
  journal  = {SoftwareX},
  keywords = {Algorithm, Software metrics, Software maintainability, Software quality},
  year     = {2020},
}

@InProceedings{8300883,
  author    = {Hariprasad, T and Vidhyagaran, G and Seenu, K. and Thirumalai, Chandrasegar},
  title     = {Software complexity analysis using halstead metrics},
  booktitle = {2017 International Conference on Trends in Electronics and Informatics (ICEI)},
  year      = {2017},
  pages     = {1109-1113},
  doi       = {10.1109/ICOEI.2017.8300883},
  keywords  = {rank5},
}

@MastersThesis{,
  author      = {Ullrich, Sebastian},
  title       = {Simple verification of rust programs via functional purification},
  institution = {Karlsruher Institut f{\"u}r Technologie (KIT)},
  year        = {2016},
}

@Unpublished{,
  author   = {Jiang, Jianfeng and Xu, Hui and Zhou, Yangfan},
  title    = {RULF: Rust Library Fuzzing via API Dependency Graph Traversal},
  year     = {2021},
  keywords = {rank2},
}

@InProceedings{8471992,
  author    = {Lindner, Marcus and Aparicius, Jorge and Lindgren, Per},
  title     = {No Panic! Verification of Rust Programs by Symbolic Execution},
  booktitle = {2018 IEEE 16th International Conference on Industrial Informatics (INDIN)},
  year      = {2018},
  pages     = {108-114},
  doi       = {10.1109/INDIN.2018.8471992},
}

@InProceedings{8122569,
  author    = {Ludwig, Jeremy and Xu, Steven and Webber, Frederick},
  title     = {Compiling static software metrics for reliability and maintainability from GitHub repositories},
  booktitle = {2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year      = {2017},
  pages     = {5-9},
  doi       = {10.1109/SMC.2017.8122569},
}

@Article{,
  author  = {Ardito, Luca and Barbato, Luca and Coppola, Riccardo and Valsesia, Michele},
  title   = {Evaluation of Rust code verbosity, understandability and complexity},
  journal = {PeerJ Computer Science},
  year    = {2021},
  date    = {2021-02-26},
  doi     = {10.7717/peerj-cs.406},
}

@InProceedings{10.1145/2818302.2818306,
  author    = {Levy, Amit and Andersen, Michael P. and Campbell, Bradford and Culler, David and Dutta, Prabal and Ghena, Branden and Levis, Philip and Pannuto, Pat},
  title     = {Ownership is Theft: Experiences Building an Embedded OS in Rust},
  booktitle = {Proceedings of the 8th Workshop on Programming Languages and Operating Systems},
  year      = {2015},
  series    = {PLOS '15},
  publisher = {Association for Computing Machinery},
  location  = {Monterey, California},
  isbn      = {9781450339421},
  pages     = {21–26},
  doi       = {10.1145/2818302.2818306},
  url       = {https://doi.org/10.1145/2818302.2818306},
  abstract  = {Rust, a new systems programming language, provides compile-time memory safety checks to help eliminate runtime bugs that manifest from improper memory management. This feature is advantageous for operating system development, and especially for embedded OS development, where recovery and debugging are particularly challenging. However, embedded platforms are highly event-based, and Rust's memory safety mechanisms largely presume threads. In our experience developing an operating system for embedded systems in Rust, we have found that Rust's ownership model prevents otherwise safe resource sharing common in the embedded domain, conflicts with the reality of hardware resources, and hinders using closures for programming asynchronously. We describe these experiences and how they relate to memory safety as well as illustrate our workarounds that preserve the safety guarantees to the largest extent possible. In addition, we draw from our experience to propose a new language extension to Rust that would enable it to provide better memory safety tools for event-driven platforms.},
  address   = {New York, NY, USA},
  keywords  = {linear types, rust, embedded operating systems, ownership},
  numpages  = {6},
}

@InProceedings{732680,
  author    = {Tracey, N. and Clark, J. and Mander, K. and McDermid, J.},
  booktitle = {Proceedings 13th IEEE International Conference on Automated Software Engineering (Cat. No.98EX239)},
  title     = {An automated framework for structural test-data generation},
  doi       = {10.1109/ASE.1998.732680},
  pages     = {285-288},
  comment   = {Das Paper erklärt verschiedene Branch Distance Funktionen für SBST.},
  file      = {:papers/An_automated_framework_for_structural_test-data_generation.pdf:PDF},
  groups    = {a72186:1},
  year      = {1998},
}

@InProceedings{6100119,
  author    = {Baars, Arthur and Harman, Mark and Hassoun, Youssef and Lakhotia, Kiran and McMinn, Phil and Tonella, Paolo and Vos, Tanja},
  booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
  title     = {Symbolic search-based testing},
  doi       = {10.1109/ASE.2011.6100119},
  pages     = {53-62},
  comment   = {Das Paper erklärt, wie die Branch Distance Funktion effizienter gestaltet werden kann, um komplizierte verschachtelte If-Konditionen zu erfüllen mit Hilfe von Dynamic Symbolic Execution.},
  groups    = {a72186:1},
  year      = {2011},
}

@Article{Khari2019,
  author   = {Khari, Manju and Kumar, Prabhat},
  title    = {An extensive evaluation of search-based software testing: a review},
  doi      = {10.1007/s00500-017-2906-y},
  issn     = {1433-7479},
  number   = {6},
  pages    = {1933-1946},
  url      = {https://doi.org/10.1007/s00500-017-2906-y},
  volume   = {23},
  abstract = {In recent years, search-based software testing (SBST) is the active research topic in software testing. SBST is the process of generating test cases that use metaheuristics for optimization of a task in the framework of software testing to solve difficult NP-hard problems. The best fitness results must be found with the heuristic search among many possibilities for a more cost-effective testing process and automate the process of generating test cases. Although search-based test data generation is a field of interest, some challenges remain unknown. The main objective of this survey is to find the main topics and trends in this emerging field of search-based software testing by examining the methods and the literature of software testing. A review of earlier studies of search-based software testing from the year 1996 to 2016 is discussed with the application of metaheuristics for the optimization of software testing.},
  comment  = {Eine systematische Übersicht über das SBST, die Hierarchie der Algorithmen usw.},
  day      = {01},
  file     = {:papers/Khari-Kumar2019_Article_AnExtensiveEvaluationOfSearch-.pdf:PDF},
  groups   = {a72186:1},
  journal  = {Soft Computing},
  month    = {Mar},
  year     = {2019},
}

@InProceedings{10.1007/11817963_38,
  author    = {Sen, Koushik and Agha, Gul},
  booktitle = {Computer Aided Verification},
  title     = {CUTE and jCUTE: Concolic Unit Testing and Explicit Path Model-Checking Tools},
  editor    = {Ball, Thomas and Jones, Robert B.},
  isbn      = {978-3-540-37411-4},
  pages     = {419--423},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {CUTE, a Concolic Unit Testing Engine for C and Java, is a tool to systematically and automatically test sequential C programs (including pointers) and concurrent Java programs. CUTE combines concrete and symbolic execution in a way that avoids redundant test cases as well as false warnings. The tool also introduces a race-flipping technique to efficiently test and model check concurrent programs with data inputs.},
  address   = {Berlin, Heidelberg},
  comment   = {jCUTE SBST Tool für Java und C, welches automatisch jUnit tests generieren und außerdem Probleme bei concurrent Programmen erkennen kann.},
  groups    = {a72186:1},
  year      = {2006},
}

@InProceedings{10.1145/800175.809889,
  author    = {Davis, Martin D. and Weyuker, Elaine J.},
  booktitle = {Proceedings of the ACM '81 Conference},
  title     = {Pseudo-Oracles for Non-Testable Programs},
  doi       = {10.1145/800175.809889},
  isbn      = {0897910494},
  pages     = {254–257},
  publisher = {Association for Computing Machinery},
  series    = {ACM '81},
  url       = {https://doi.org/10.1145/800175.809889},
  abstract  = {The most commonly used method of validating a program is by testing. The programmer typically runs the program on some test cases, and if and when they run correctly, the program is considered to be correct.We know that many difficult problems are associated with testing. One such problem is that it is a fundamental part of the testing process to require the ability to infer properties of a program by observing the program's behavior on selected inputs. The most common property that one hopes to infer through testing is correctness. But unless the program is run on the entire input domain, there are infinitely many programs which produce the correct output on the selected inputs, but produce incorrect output for some other element of the domain.},
  address   = {New York, NY, USA},
  comment   = {Das Paper beschreibt die Pseudo-Orakel für non-testable Programme. Diese werden dadurch realisiert, dass ein SUT von zwei Teams unabhängig implementiert wird (mittels zwei verschiedenen Sprachen) und die Ausgaben dieser beiden Programmen, die nach Spezifikation äquivalent sein sollten, werden verglichen.},
  file      = {:papers/800175.809889.pdf:PDF},
  groups    = {a72186:1},
  numpages  = {4},
  year      = {1981},
}

@InProceedings{10.1145/1569901.1570127,
  author    = {McMinn, Phil},
  booktitle = {Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation},
  title     = {Search-Based Failure Discovery Using Testability Transformations to Generate Pseudo-Oracles},
  doi       = {10.1145/1569901.1570127},
  isbn      = {9781605583259},
  location  = {Montreal, Qu\'{e}bec, Canada},
  pages     = {1689–1696},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '09},
  url       = {https://doi.org/10.1145/1569901.1570127},
  abstract  = {Testability transformations are source-to-source program transformations that are designed to improve the testability of a program. This paper introduces a novel approach in which transformations are used to improve testability of a program by generating a pseudo-oracle. A pseudo-oracle is an alternative version of a program under test whose output can be compared with the original. Differences in output between the two programs may indicate a fault in the original program. Two transformations are presented. The first can highlight numerical inaccuracies in programs and cumulative roundoff errors, whilst the second may detect the presence of race conditions in multi-threaded code.Once a pseudo-oracle is generated, techniques are applied from the field of search-based testing to automatically find differences in output between the two versions of the program. The results of an experimental study presented in the paper show that both random testing and genetic algorithms are capable of utilizing the pseudo-oracles to automatically find program failures.Using genetic algorithms it is possible to explicitly maximize the discrepancies between the original programs and their pseudo-oracles. This allows for the production of test cases where the observable failure is highly pronounced, enabling the tester to establish the seriousness of the underlying fault.},
  address   = {New York, NY, USA},
  comment   = {Das Paper baut auf dem Originalpaper von Davis und Weyuker über Pseudo-Orakel und versucht, solche Pseudo-Orakel automatisch zu generieren, um ein zweites Program zu erstellen, welches die gleichen Outputs haben sollte.},
  file      = {:papers/1569901.1570127.pdf:PDF},
  groups    = {a72186:1},
  keywords  = {search-based software testing, testability transformation, non-testable program, oracle, program transformation, pseudo-oracle},
  numpages  = {8},
  year      = {2009},
}

@InProceedings{528535,
  author    = {Offutt, A.J.},
  booktitle = {Proceedings., International Test Conference},
  title     = {A practical system for mutation testing: help for the common programmer},
  doi       = {10.1109/TEST.1994.528535},
  pages     = {824-830},
  comment   = {Grundlagen von Mutation Testing in Unit-Tests.},
  groups    = {a72186:1},
  year      = {1994},
}

@Article{1265732,
  author  = {Harman, M. and Hu, L. and Hierons, R. and Wegener, J. and Sthamer, H. and Baresel, A. and Roper, M.},
  title   = {Testability transformation},
  doi     = {10.1109/TSE.2004.1265732},
  number  = {1},
  pages   = {3-16},
  volume  = {30},
  comment = {Quellcode-zu-Quellcode Transformationen, um bessere Performanz für Testgenerierung zu kriegen. Dabei wird ein SUT unter bestimmten Transformationen zu einem ähnlichen Programm umgewandelt.},
  file    = {:papers/01265732.pdf:PDF},
  groups  = {a72186:1},
  journal = {IEEE Transactions on Software Engineering},
  year    = {2004},
}

@InProceedings{10.1145/1450058.1450087,
  author    = {Godefroid, Patrice and Levin, Michael Y. and Molnar, David A.},
  booktitle = {Proceedings of the 8th ACM International Conference on Embedded Software},
  title     = {Active Property Checking},
  doi       = {10.1145/1450058.1450087},
  isbn      = {9781605584683},
  location  = {Atlanta, GA, USA},
  pages     = {207–216},
  publisher = {Association for Computing Machinery},
  series    = {EMSOFT '08},
  url       = {https://doi.org/10.1145/1450058.1450087},
  abstract  = {Runtime property checking (as implemented in tools like Purify or Valgrind) checks whether a program execution satisfies a property. Active property checking extends runtime checking by checking whether the property is satisfied by all program executions that follow the same program path. This check is performed on a symbolic execution of the given program path using a constraint solver. If the check fails, the constraint solver generates an alternative program input triggering a new program execution that follows the same program path but exhibits a property violation. Combined with systematic dynamic test generation, which attempts to exercise all feasible paths in a program, active property checking defines a new form of dynamic software model checking (program verification). In this paper, we formalize and study active property checking. We show how static and dynamic type checking can be extended with active type checking. Then, we discuss how to implement active property checking efficiently. Finally, we discuss results of experiments with media playing applications on Windows, where active property checking was able to detect several new security-related bugs.},
  address   = {New York, NY, USA},
  comment   = {Testability Transformation, um für bestimmte Fehler wie DivisionByZero oder IndexOutOfBounds einen eigenen Branch zu erstellen, wodurch die Suche in bestimmte Richtung gelenkt werden kann.},
  groups    = {a72186:1},
  keywords  = {symbolic execution, security, software testing},
  numpages  = {10},
  year      = {2008},
}

@Article{GUO2016204,
  author   = {Hai-Feng Guo},
  title    = {A semantic approach for automated test oracle generation},
  doi      = {https://doi.org/10.1016/j.cl.2016.01.006},
  issn     = {1477-8424},
  pages    = {204-219},
  url      = {https://www.sciencedirect.com/science/article/pii/S147784241530021X},
  volume   = {45},
  abstract = {This paper presents the design, implementation, and applications of a software testing tool, TAO, which allows users to specify and generate test cases and oracles in a declarative way. Extended from its previous grammar-based test generation tool, TAO provides a declarative notation for defining denotational semantics on each productive grammar rule, such that when a test case is generated, its expected semantics will be evaluated automatically as well, serving as its test oracle. TAO further provides a simple tagging mechanism to embed oracles into test cases for bridging the automation between test case generation and software testing. Two practical case studies are used to illustrate how automated oracle generation can be effectively integrated with grammar-based test generation in different testing scenarios: locating fault-inducing input patterns on Java applications; and Selenium-based automated web testing.},
  comment  = {Explizite Tags als Orakel für Testgenerierung.},
  groups   = {a72186:1},
  journal  = {Computer Languages, Systems \& Structures},
  keywords = {Software testing, Test case generation, Test oracle, Denotational semantics},
  year     = {2016},
}

@Article{10.1145/3293455,
  author     = {Arcuri, Andrea},
  title      = {RESTful API Automated Test Case Generation with EvoMaster},
  doi        = {10.1145/3293455},
  issn       = {1049-331X},
  number     = {1},
  url        = {https://doi.org/10.1145/3293455},
  volume     = {28},
  abstract   = {RESTful APIs are widespread in industry, especially in enterprise applications developed with a microservice architecture. A RESTful web service will provide data via an API over the network using HTTP, possibly interacting with databases and other web services. Testing a RESTful API poses challenges, because inputs/outputs are sequences of HTTP requests/responses to a remote server. Many approaches in the literature do black-box testing, because often the tested API is a remote service whose code is not available. In this article, we consider testing from the point of view of the developers, who have full access to the code that they are writing. Therefore, we propose a fully automated white-box testing approach, where test cases are automatically generated using an evolutionary algorithm. Tests are rewarded based on code coverage and fault-finding metrics. However, REST is not a protocol but rather a set of guidelines on how to design resources accessed over HTTP endpoints. For example, there are guidelines on how related resources should be structured with hierarchical URIs and how the different HTTP verbs should be used to represent well-defined actions on those resources. Test-case generation for RESTful APIs that only rely on white-box information of the source code might not be able to identify how to create prerequisite resources needed before being able to test some of the REST endpoints. Smart sampling techniques that exploit the knowledge of best practices in RESTful API design are needed to generate tests with predefined structures to speed up the search. We implemented our technique in a tool called EvoMaster, which is open source. Experiments on five open-source, yet non-trivial, RESTful services show that our novel technique automatically found 80 real bugs in those applications. However, obtained code coverage is lower than the one achieved by the manually written test suites already existing in those services. Research directions on how to further improve such an approach are therefore discussed, such as the handling of SQL databases.},
  address    = {New York, NY, USA},
  articleno  = {3},
  comment    = {SBST für REST APIs mit Orakel Generierung.},
  groups     = {a72186:1},
  issue_date = {February 2019},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  keywords   = {REST, testing, web service, Software engineering},
  month      = jan,
  numpages   = {37},
  publisher  = {Association for Computing Machinery},
  year       = {2019},
}

@Article{6963470,
  author  = {Barr, Earl T. and Harman, Mark and McMinn, Phil and Shahbaz, Muzammil and Yoo, Shin},
  title   = {The Oracle Problem in Software Testing: A Survey},
  doi     = {10.1109/TSE.2014.2372785},
  number  = {5},
  pages   = {507-525},
  volume  = {41},
  comment = {Beschreibt Arten von Orakel (automatische und manuelle) und wie sie zusammenhängen.},
  file    = {:6963470 - The Oracle Problem in Software Testing_ a Survey.pdf:PDF},
  groups  = {a72186:1},
  journal = {IEEE Transactions on Software Engineering},
  year    = {2015},
}

@InProceedings{5954405,
  author    = {McMinn, Phil},
  booktitle = {2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops},
  title     = {Search-Based Software Testing: Past, Present and Future},
  doi       = {10.1109/ICSTW.2011.100},
  pages     = {153-163},
  comment   = {Eine gute Übersicht was SBST überhaupt ist und welche Arten von SBST momentan verbreitet sind: temporal testing, structural testing, functional testing, mit realen Anwendungsbeispielen.},
  file      = {:papers/Search-Based_Software_Testing_Past_Present_and_Future.pdf:PDF},
  groups    = {a72186:1},
  keywords  = {rank5},
  year      = {2011},
}

@InProceedings{10.1145/1062455.1062530,
  author    = {Andrews, J. H. and Briand, L. C. and Labiche, Y.},
  booktitle = {Proceedings of the 27th International Conference on Software Engineering},
  title     = {Is Mutation an Appropriate Tool for Testing Experiments?},
  doi       = {10.1145/1062455.1062530},
  isbn      = {1581139632},
  location  = {St. Louis, MO, USA},
  pages     = {402–411},
  publisher = {Association for Computing Machinery},
  series    = {ICSE '05},
  url       = {https://doi.org/10.1145/1062455.1062530},
  abstract  = {The empirical assessment of test techniques plays an important role in software testing research. One common practice is to instrument faults, either manually or by using mutation operators. The latter allows the systematic, repeatable seeding of large numbers of faults; however, we do not know whether empirical results obtained this way lead to valid, representative conclusions. This paper investigates this important question based on a number of programs with comprehensive pools of test cases and known faults. It is concluded that, based on the data available thus far, the use of mutation operators is yielding trustworthy results (generated mutants are similar to real faults). Mutants appear however to be different from hand-seeded faults that seem to be harder to detect than real faults.},
  address   = {New York, NY, USA},
  comment   = {Eine empirische Forschung, die zeigt, dass Test Suites, die gut im Finden von Mutanten sind, sind auch gut im Finden von echten Bugs.},
  groups    = {a72186:1},
  keywords  = {hand-seeded faults, real faults, mutants},
  numpages  = {10},
  year      = {2005},
}

@InProceedings{Fraser2011,
  author    = {Fraser, Gordon and Arcuri, Andrea},
  booktitle = {2011 Fourth IEEE International Conference on Software Testing, Verification and Validation},
  title     = {It is Not the Length That Matters, It is How You Control It},
  doi       = {10.1109/ICST.2011.54},
  pages     = {150-159},
  abstract  = {The length of test cases is a little investigated topic in search-based test generation for object oriented software, where test cases are sequences of method calls. While intuitively longer tests can achieve higher overall code coverage, there is always the threat of bloat - a complex phenomenon in evolutionary computation, where the length abnormally grows over time. In this paper, we show that bloat indeed also occurs in the context of test generation for object oriented software. We present different techniques to overcome the problem of length bloat, and evaluate all possible combinations of these techniques using different search lengths. Experiments on a set of difficult search targets selected from several open source and industrial projects show that the important choice in search-based testing is not the length of test cases, but how to make sure that this length does not become bloated.},
  comment   = {Es werden Techniken vorgestellt, um generierte Tests so klein wie möglich zu halten und Bloating zu vermeiden. Außerdem wird die Berechnung und Normalisierung der Branch und Approach Distance erklärt. Zudem werden die Crossover, Selection und Mutation Operatoren anhand von Beispielen erklärt. 
Insgesamt wird im Paper jeder Schritt der Generierung und Evolution relativ genau erklärt.},
  file      = {:papers/05770604.pdf:PDF},
  groups    = {a72186:1},
  issn      = {2159-4848},
  keywords  = {rank5},
  month     = {March},
  year      = {2011},
}

@InProceedings{5477052,
  author    = {Arcuri, Andrea},
  booktitle = {2010 Third International Conference on Software Testing, Verification and Validation},
  title     = {Longer is Better: On the Role of Test Sequence Length in Software Testing},
  doi       = {10.1109/ICST.2010.16},
  pages     = {469-478},
  abstract  = {In the presence of an internal state, often it is required a sequence of function calls to test software. In fact, to cover a particular branch of the code, a sequence of previous function calls might be required to put the internal state in the appropriate configuration. Internal states are not only present in object-oriented software, but also in procedural software(e.g., static variables in C programs). In the literature, there are many techniques to test this type of software. However, to our best knowledge, the properties related to choosing the length of these sequences have received only little attention in the literature. In this paper, we analyse the role that the length plays in software testing, in particular branch coverage. We show that on “difficult” software testing benchmarks longer test sequences make their testing trivial. Hence, we argue that the choice of the length of the test sequences is very important in software testing.},
  comment   = {Arcuri untersucht, dass die Länge der Tests direkt mit der Coverage der Tests korreliert.},
  groups    = {a72186:1},
  issn      = {2159-4848},
  keywords  = {rank4},
  month     = {April},
  year      = {2010},
}

@Article{whitley1994genetic,
  author    = {Whitley, Darrell},
  title     = {A genetic algorithm tutorial},
  number    = {2},
  pages     = {65--85},
  volume    = {4},
  comment   = {Einführung in genetische Algorithmen},
  groups    = {a72186:1},
  journal   = {Statistics and computing},
  publisher = {Springer},
  year      = {1994},
}

@Article{WHITLEY2001817,
  author   = {Darrell Whitley},
  title    = {An overview of evolutionary algorithms: practical issues and common pitfalls},
  doi      = {https://doi.org/10.1016/S0950-5849(01)00188-4},
  issn     = {0950-5849},
  number   = {14},
  pages    = {817-831},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950584901001884},
  volume   = {43},
  abstract = {An overview of evolutionary algorithms is presented covering genetic algorithms, evolution strategies, genetic programming and evolutionary programming. The schema theorem is reviewed and critiqued. Gray codes, bit representations and real-valued representations are discussed for parameter optimization problems. Parallel Island models are also reviewed, and the evaluation of evolutionary algorithms is discussed.},
  comment  = {Eine weiterführende Einführung in die genetischen Algorithmen},
  groups   = {a72186:1},
  journal  = {Information and Software Technology},
  keywords = {Genetic algorithms, Evolution strategies, Genetic programming, Evolutionary programming, Search, Automated programming, Parallel algorithms},
  year     = {2001},
}

@Article{BUHLER20083144,
  author   = {Oliver Bühler and Joachim Wegener},
  title    = {Evolutionary functional testing},
  doi      = {https://doi.org/10.1016/j.cor.2007.01.015},
  issn     = {0305-0548},
  note     = {Part Special Issue: Search-based Software Engineering},
  number   = {10},
  pages    = {3144-3160},
  url      = {https://www.sciencedirect.com/science/article/pii/S0305054807000329},
  volume   = {35},
  abstract = {The development and testing of software-based systems is an essential activity for the automotive industry. The 50–70 software-based systems with different complexities and developed by various suppliers are installed in today's premium vehicles, communicating with each other via different bus systems. The integration and testing of systems of this complexity is a very challenging task. The aim of testing is to detect faults in the systems under test and to convey confidence in the correct functioning of the systems if no faults are found during comprehensive testing. Faults not found in the different testing phases could have significant consequences that range from customer dissatisfaction to damage of physical property or, in safety-relevant areas, even to the endangering of human lives. Therefore, the thorough testing of developed systems is essential. Evolutionary testing tries to improve the effectiveness and efficiency of the testing process by transforming testing objectives into search problems, and applying evolutionary computation in order to solve them. The most important class of testing methods is functional testing. However, functional testing is difficult to automate by evolutionary testing. This work will describe how evolutionary testing could be applied to automate functional testing in general and the testing of complex automotive systems in particular. It presents two case studies and shows how evolutionary testing is effective at finding faults in the functional behaviour of these systems. In addition, a quantitative comparison with manual and random test case selection is done for one application.},
  comment  = {DaimlerChrysler SBST für funktionales Testen der automatischen Einparkhilfe},
  groups   = {a72186:1},
  journal  = {Computers \& Operations Research},
  keywords = {Software testing, Functional testing, Evolutionary testing, Evolutionary functional testing, Testing process, Automotive systems},
  year     = {2008},
}

@InProceedings{Shamshiri2015,
  author    = {Shamshiri, Sina and Just, Rene and Rojas, Jos\'{e} Miguel and Fraser, Gordon and McMinn, Phil and Arcuri, Andrea},
  booktitle = {International Conference on Automated Software Engineering (ASE 2015)},
  title     = {Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges},
  pages     = {201--211},
  publisher = {ACM},
  comment   = {Noch zu lesen},
  groups    = {a72186:1},
  year      = {2015},
}

@Article{Fraser2015,
  author   = {Fraser, Gordon and Arcuri, Andrea and McMinn, Phil},
  title    = {A Memetic Algorithm for Whole Test Suite Generation},
  pages    = {311--327},
  volume   = {103},
  comment  = {Feingranulare Erweiterung der genetischen Algorithme, noch zu lesen},
  groups   = {a72186:1},
  journal  = {Journal of Systems and Software},
  keywords = {rank4},
  year     = {2015},
}

@InProceedings{6200103,
  author    = {Fraser, Gordon and Arcuri, Andrea},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  title     = {The Seed is Strong: Seeding Strategies in Search-Based Software Testing},
  doi       = {10.1109/ICST.2012.92},
  pages     = {121-130},
  comment   = {Das Paper erklärt, wie SBST mit bestimmten Seedingstechniken anstatt von Random Initial Population bessere erzielen könnte.},
  groups    = {a72186:1},
  year      = {2012},
}

@InProceedings{10.1145/1143997.1144316,
  author    = {Tlili, Marouane and Wappler, Stefan and Sthamer, Harmen},
  booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
  title     = {Improving Evolutionary Real-Time Testing},
  doi       = {10.1145/1143997.1144316},
  isbn      = {1595931864},
  location  = {Seattle, Washington, USA},
  pages     = {1917–1924},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '06},
  url       = {https://doi.org/10.1145/1143997.1144316},
  abstract  = {Embedded systems are often used in a safety-critical context, e.g. in airborne or vehicle systems. Typically, timing constraints must be satisfied so that real-time embedded systems work properly and safely. Execution time testing involves finding the best and worst case execution times to determine if timing constraints are respected. Evolutionary real-time testing (ERTT) is used to dynamically search for the extreme execution times. It can be shown that ERTT outperforms the traditional methods based on static analysis. However, during the evolutionary search, some parts of the source code are never accessed. Moreover, it turns out that ERTT delivers different extreme execution times in a high number of generations for the same test object, the results are neither reliable nor efficient. We propose a new approach to ERTT which makes use of seeding the evolutionary algorithm with test data achieving a high structural coverage. Using such test data ensures a comprehensive exploration of the search space and leads to rise the confidence in the results. We present also another improvement method based on restricting the range of the input variables in the initial population in order to reduce the search space. Experiments with these approaches demonstrate an increase of reliability in terms of constant extreme execution times and a gain in efficiency in terms of number of generations needed.},
  address   = {New York, NY, USA},
  comment   = {DaimlerChrysler versucht in dem Paper, die kritischen Echtzeitsysteme mit Hilfe von SBST zu testen, indem die möglichst schlechte Ausführungszeit gesucht wird.},
  groups    = {a72186:1},
  keywords  = {software tools, software engineering},
  numpages  = {8},
  year      = {2006},
}

@Misc{StackOverflow2020,
  author  = {{Stack Overflow}},
  title   = {{Stack Overflow Developer Survey 2020}},
  url     = {https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages-loved},
  urldate = {2021-05-02},
  groups  = {a72186:1},
  year    = {2020},
}

@Misc{Rust10,
  author  = {{The Rust Core Team}},
  date    = {2015-05-15},
  title   = {Announcing Rust 1.0},
  url     = {https://blog.rust-lang.org/2015/05/15/Rust-1.0.html},
  urldate = {2021-06-28},
  groups  = {a72186:1},
  year    = {2015},
}

@InProceedings{cadar2008klee,
  author     = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
  booktitle  = {OSDI},
  title      = {KLEE: unassisted and automatic generation of high-coverage tests for complex systems programs.},
  pages      = {209--224},
  volume     = {8},
  file       = {:papers/cadar.pdf:PDF},
  groups     = {State of the Art Tools, a72186:1},
  readstatus = {skimmed},
  year       = {2008},
}

@Misc{Microsoft2019MemoryBugs,
  author   = {Matt Miller},
  title    = {Trends, challenges, and strategic shifts in the software vulnerability mitigation landscape},
  year     = {2019},
  date     = {2019-02-07},
  url      = {https://github.com/Microsoft/MSRC-Security-Research/blob/master/presentations/2019_02_BlueHatIL/2019_01%20-%20BlueHatIL%20-%20Trends%2C%20challenge%2C%20and%20shifts%20in%20software%20vulnerability%20mitigation.pdf},
  urldate  = {2021-06-28},
  comment  = {Microfosft's Präsentation über die Anzahl von Speicher-spezifischen Bugs in ihrer Software.},
  keywords = {microsoft, memory},
}

@Misc{MicrosoftJoinsRust,
  author  = {Nell Shamrell-Harrington},
  title   = {Microsoft joins Rust Foundation},
  year    = {2021},
  date    = {2021-02-08},
  url     = {https://cloudblogs.microsoft.com/opensource/2021/02/08/microsoft-joins-rust-foundation/},
  urldate = {2021-06-28},
  comment = {Microsoft Blog erzählt, dass Microsoft in OSS Rust Foundation eingestiegen ist.},
}

@Misc{FutureOfRust,
  author  = {Cameron Manavian},
  title   = {Post-Mozilla Rust: The Future of the Rust Language},
  year    = {2020},
  date    = {2020-08-19},
  url     = {https://medium.com/the-innovation/post-mozilla-rust-the-future-of-the-rust-language-61a5cfb1f615},
  comment = {The companies that love Rust.},
}

@Misc{AmazonLovesRust,
  author  = {Matt Asay},
  title   = {Why AWS loves Rust, and how we'd like to help},
  year    = {2020},
  date    = {2020-11-24},
  url     = {https://aws.amazon.com/de/blogs/opensource/why-aws-loves-rust-and-how-wed-like-to-help/},
  urldate = {2021-06-28},
}

@Misc{RustInAndroid,
  author = {Stoep, Jeff Vander and Hines, Stephen},
  title  = {Rust in the Android platform},
  year   = {2021},
  date   = {2021-04-06},
  url    = {https://security.googleblog.com/2021/04/rust-in-android-platform.html},
}

@Misc{GoogleRustFoundation,
  author  = {Lars Bergstrom},
  title   = {Google joins the Rust Foundation},
  year    = {2021},
  date    = {2021-02-08},
  url     = {https://opensource.googleblog.com/2021/02/google-joins-rust-foundation.html},
  comment = {Google über ihre Systeme, die mit Rust geschrieben wurden.},
}

@Misc{,
  author = {Disselkoen, Craig and Ayers, Hudson},
  title  = {haybale: Symbolic execution of LLVM IR},
  groups = {State of the Art Tools},
}

@Misc{,
  comment = {Der Testgenerator, der LLVM IR verwendet, um darauf mit Hilfe von DSE Tests zu generieren. Außerdem beschreiben die Autoren mehrere Techniken, wie sie Seiteneffekte wie Schreiben oder Lesen in Dateien oder Umgebungsvariablen behandeln.},
  groups  = {State of the Art Tools},
}

@Article{Panichella_2015,
  author    = {Annibale Panichella and Fitsum Meshesha Kifetew and Paolo Tonella},
  title     = {Reformulating Branch Coverage as a Many-Objective Optimization Problem},
  doi       = {10.1109/ICST.2015.7102604},
  booktitle = {2015 {IEEE} 8th International Conference on Software Testing, Verification and Validation ({ICST})},
  comment   = {Der MOSA Algorithmus.},
  file      = {:papers/07102604.pdf:PDF},
  groups    = {a72186:1},
  month     = {apr},
  publisher = {{IEEE}},
  year      = {2015},
}

@Article{Fraser_2013,
  author    = {Gordon Fraser and Andrea Arcuri},
  title     = {Whole Test Suite Generation},
  doi       = {10.1109/TSE.2012.14},
  number    = {2},
  pages     = {276--291},
  volume    = {39},
  file      = {:papers/06152257.pdf:PDF;:Fraser_2013 - Whole Test Suite Generation.pdf:PDF},
  groups    = {a72186:1},
  journal   = {{IEEE} Transactions on Software Engineering},
  month     = {feb},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year      = {2013},
}

@Article{10.1145/103162.103163,
  author     = {Goldberg, David},
  title      = {What Every Computer Scientist Should Know about Floating-Point Arithmetic},
  doi        = {10.1145/103162.103163},
  issn       = {0360-0300},
  number     = {1},
  pages      = {5–48},
  url        = {https://doi.org/10.1145/103162.103163},
  volume     = {23},
  abstract   = {Floating-point arithmetic is considered as esoteric subject by many people. This is
rather surprising, because floating-point is ubiquitous in computer systems: Almost
every language has a floating-point datatype; computers from PCs to supercomputers
have floating-point accelerators; most compilers will be called upon to compile floating-point
algorithms from time to time; and virtually every operating system must respond to
floating-point exceptions such as overflow. This paper presents a tutorial on the
aspects of floating-point that have a direct impact on designers of computer systems.
It begins with background on floating-point representation and rounding error, continues
with a discussion of the IEEE floating point standard, and concludes with examples
of how computer system builders can better support floating point.},
  address    = {New York, NY, USA},
  file       = {:papers/103162.103163.pdf:PDF},
  issue_date = {March 1991},
  journal    = {ACM Comput. Surv.},
  keywords   = {ulp, rounding error, guard digit, floating-point, NaN, gradual underflow, rounding mode, overflow, denormalized number, relative error, underflow, floating-point standard, exception},
  month      = mar,
  numpages   = {44},
  publisher  = {Association for Computing Machinery},
  year       = {1991},
}

@Article{Fraser_2013,
  author    = {Gordon Fraser and Andrea Arcuri},
  title     = {1600 faults in 100 projects: automatically finding faults while achieving high coverage with {EvoSuite}},
  doi       = {10.1007/s10664-013-9288-2},
  number    = {3},
  pages     = {611--639},
  volume    = {20},
  file      = {:Fraser_2013 - 1600 Faults in 100 Projects_ Automatically Finding Faults While Achieving High Coverage with EvoSuite.pdf:PDF},
  journal   = {Empirical Software Engineering},
  month     = {nov},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2013},
}

@Article{Fraser_2011,
  author    = {Gordon Fraser and Andrea Arcuri},
  title     = {{EvoSuite}},
  doi       = {10.1145/2025113.2025179},
  booktitle = {Proceedings of the 19th {ACM} {SIGSOFT} symposium and the 13th European conference on Foundations of software engineering - {SIGSOFT}/{FSE} {\textquotesingle}11},
  file      = {:papers/2025113.2025179.pdf:PDF},
  publisher = {{ACM} Press},
  year      = {2011},
}

@Article{Fraser_2011,
  author    = {Gordon Fraser and Andrea Arcuri},
  title     = {Evolutionary Generation of Whole Test Suites},
  doi       = {10.1109/QSIC.2011.19},
  booktitle = {2011 11th International Conference on Quality Software},
  file      = {:papers/06004309.pdf:PDF},
  month     = {jul},
  publisher = {{IEEE}},
  year      = {2011},
}

@Article{Goldberg_1994,
  author    = {Allen Goldberg and T. C. Wang and David Zimmerman},
  title     = {Applications of feasible path analysis to program testing},
  doi       = {10.1145/186258.186523},
  booktitle = {Proceedings of the 1994 international symposium on Software testing and analysis - {ISSTA} {\textquotesingle}94},
  publisher = {{ACM} Press},
  year      = {1994},
}

@Article{Pacheco_2007,
  author    = {Carlos Pacheco and Michael D. Ernst},
  title     = {Randoop: feedback-directed random testing for Java},
  doi       = {10.1145/1297846.1297902},
  booktitle = {Companion to the 22nd {ACM} {SIGPLAN} conference on Object oriented programming systems and applications companion - {OOPSLA} {\textquotesingle}07},
  publisher = {{ACM} Press},
  year      = {2007},
}

@Article{Godefroid_2005,
  author    = {Patrice Godefroid and Nils Klarlund and Koushik Sen},
  title     = {DART: directed automated random testing},
  doi       = {10.1145/1065010.1065036},
  booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} conference on Programming language design and implementation - {PLDI} {\textquotesingle}05},
  publisher = {{ACM} Press},
  year      = {2005},
}

@Article{McMinn_2004,
  author    = {Phil McMinn},
  title     = {Search-based software test data generation: a survey},
  doi       = {10.1002/stvr.294},
  number    = {2},
  pages     = {105--156},
  volume    = {14},
  comment   = {Es wird auch die rekursive Berechnung der Branch Distance erklärt.},
  file      = {:papers/stvr.294.pdf:PDF},
  journal   = {Software Testing, Verification and Reliability},
  month     = {may},
  publisher = {Wiley},
  year      = {2004},
}

@Article{Arcuri_2011,
  author    = {Andrea Arcuri},
  title     = {It really does matter how you normalize the branch distance in search-based software testing},
  doi       = {10.1002/stvr.457},
  number    = {2},
  pages     = {119--147},
  volume    = {23},
  journal   = {Software Testing, Verification and Reliability},
  month     = {mar},
  publisher = {Wiley},
  year      = {2011},
}

@InProceedings{Harman2002,
  author    = {Harman, M. and Fox, C. and Hierons, R. and Lin Hu and Danicic, S. and Wegener, J.},
  booktitle = {Proceedings. Second IEEE International Workshop on Source Code Analysis and Manipulation},
  title     = {VADA: a transformation-based system for variable dependence analysis},
  doi       = {10.1109/SCAM.2002.1134105},
  pages     = {55-64},
  year      = {2002},
}

@Article{Arcuri_2013,
  author    = {Andrea Arcuri and Gordon Fraser},
  title     = {Parameter tuning or default values? An empirical investigation in search-based software engineering},
  doi       = {10.1007/s10664-013-9249-9},
  number    = {3},
  pages     = {594--623},
  volume    = {18},
  journal   = {Empirical Software Engineering},
  month     = {feb},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2013},
}

@Article{Arcuri_2014,
  author    = {Andrea Arcuri and Gordon Fraser},
  title     = {On the Effectiveness of Whole Test Suite Generation},
  doi       = {10.1007/978-3-319-09940-8_1},
  pages     = {1--15},
  booktitle = {Search-Based Software Engineering},
  publisher = {Springer International Publishing},
  year      = {2014},
}

@Article{Deb_2000,
  author    = {Kalyanmoy Deb and Samir Agrawal and Amrit Pratap and T Meyarivan},
  title     = {A Fast Elitist Non-dominated Sorting Genetic Algorithm for Multi-objective Optimization: {NSGA}-{II}},
  doi       = {10.1007/3-540-45356-3_83},
  pages     = {849--858},
  booktitle = {Parallel Problem Solving from Nature {PPSN} {VI}},
  comment   = {Der NSGA II Algorithmus.},
  file      = {:papers/nsga2.pdf:PDF},
  publisher = {Springer Berlin Heidelberg},
  year      = {2000},
}

@Article{Babi__2011,
  author    = {Domagoj Babi{\'{c}} and Lorenzo Martignoni and Stephen McCamant and Dawn Song},
  title     = {Statically-directed dynamic automated test generation},
  doi       = {10.1145/2001420.2001423},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing and Analysis - {ISSTA} {\textquotesingle}11},
  comment   = {Der Autor beschreibt vor allem Probleme einer Testgenerierung, die auf Binaries und nicht auf Souce Code Level statt findet. Das könnte man als einen Gegenpunkt bei KLEE und anderen Testgeneratoren für Rust verwenden.},
  file      = {:papers/2001420.2001423.pdf:PDF},
  publisher = {{ACM} Press},
  year      = {2011},
}

@Article{Myers2012,
  title     = {The Art of Software Testing},
  doi       = {10.1002/9781119202486},
  editor    = {Glenford J. Myers and Tom Badgett and Corey Sandler},
  month     = {jan},
  publisher = {Wiley},
  year      = {2012},
}

@InProceedings{Harman2015,
  author    = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
  booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
  title     = {Achievements, Open Problems and Challenges for Search Based Software Testing},
  doi       = {10.1109/ICST.2015.7102580},
  pages     = {1-12},
  comment   = {TODO},
  file      = {:papers/Achievements_Open_Problems_and_Challenges_for_Search_Based_Software_Testing.pdf:PDF},
  year      = {2015},
}

@InProceedings{Campos2017,
  author    = {Campos, Jos{\'e} and Ge, Yan and Fraser, Gordon and Eler, Marcelo and Arcuri, Andrea},
  booktitle = {Search Based Software Engineering},
  title     = {An Empirical Evaluation of Evolutionary Algorithms for Test Suite Generation},
  editor    = {Menzies, Tim and Petke, Justyna},
  isbn      = {978-3-319-66299-2},
  pages     = {33--48},
  publisher = {Springer International Publishing},
  abstract  = {Evolutionary algorithms have been shown to be effective at generating unit test suites optimised for code coverage. While many aspects of these algorithms have been evaluated in detail (e.g., test length and different kinds of techniques aimed at improving performance, like seeding), the influence of the specific algorithms has to date seen less attention in the literature. As it is theoretically impossible to design an algorithm that is best on all possible problems, a common approach in software engineering problems is to first try a Genetic Algorithm, and only afterwards try to refine it or compare it with other algorithms to see if any of them is more suited for the addressed problem. This is particularly important in test generation, since recent work suggests that random search may in practice be equally effective, whereas the reformulation as a many-objective problem seems to be more effective. To shed light on the influence of the search algorithms, we empirically evaluate six different algorithms on a selection of non-trivial open source classes. Our study shows that the use of a test archive makes evolutionary algorithms clearly better than random testing, and it confirms that the many-objective search is the most effective.},
  address   = {Cham},
  comment   = {TODO},
  file      = {:papers/CR.pdf:PDF},
  year      = {2017},
}

@Article{10.1145/1013886.1007528,
  author     = {Tonella, Paolo},
  title      = {Evolutionary Testing of Classes},
  doi        = {10.1145/1013886.1007528},
  issn       = {0163-5948},
  number     = {4},
  pages      = {119–128},
  url        = {https://doi.org/10.1145/1013886.1007528},
  volume     = {29},
  abstract   = {Object oriented programming promotes reuse of classes in multiple contexts. Thus,
a class is designed and implemented with several usage scenarios in mind, some of
which possibly open and generic. Correspondingly, the unit testing of classes cannot
make too strict assumptions on the actual method invocation sequences, since these
vary from application to application.In this paper, a genetic algorithm is exploited
to automatically produce test cases for the unit testing of classes in a generic usage
scenario. Test cases are described by chromosomes, which include information on which
objects to create, which methods to invoke and which values to use as inputs. The
proposed algorithm mutates them with the aim of maximizing a given coverage measure.
The implementation of the algorithm and its application to classes from the Java standard
library are described.},
  address    = {New York, NY, USA},
  comment    = {TODO, Single Objectiva at a time approach. 
Objekt-orientierte Programmierung und Klassen werden bei der genetischen Suche berücksichtigt.},
  file       = {:papers/1013886.1007528.pdf:PDF},
  issue_date = {July 2004},
  journal    = {SIGSOFT Softw. Eng. Notes},
  keywords   = {genetic algorithms, object-oriented testing, automated test case generation},
  month      = jul,
  numpages   = {10},
  publisher  = {Association for Computing Machinery},
  year       = {2004},
}

@InProceedings{Harman2010,
  author    = {Harman, Mark and Kim, Sung Gon and Lakhotia, Kiran and McMinn, Phil and Yoo, Shin},
  booktitle = {2010 Third International Conference on Software Testing, Verification, and Validation Workshops},
  title     = {Optimizing for the Number of Tests Generated in Search Based Test Data Generation with an Application to the Oracle Cost Problem},
  doi       = {10.1109/ICSTW.2010.31},
  pages     = {182-191},
  year      = {2010},
}

@Article{Korel1990,
  author  = {Korel, B.},
  title   = {Automated software test data generation},
  doi     = {10.1109/32.57624},
  number  = {8},
  pages   = {870-879},
  volume  = {16},
  comment = {TODO Original Paper über Branch Distance.},
  journal = {IEEE Transactions on Software Engineering},
  year    = {1990},
}

@Article{Wegener2001,
  author   = {Joachim Wegener and Andre Baresel and Harmen Sthamer},
  title    = {Evolutionary test environment for automatic structural testing},
  doi      = {https://doi.org/10.1016/S0950-5849(01)00190-2},
  issn     = {0950-5849},
  number   = {14},
  pages    = {841-854},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950584901001902},
  volume   = {43},
  abstract = {Testing is the most significant analytic quality assurance measure for software. Systematic design of test cases is crucial for the test quality. Structure-oriented test methods, which define test cases on the basis of the internal program structures, are widely used. A promising approach for the automation of structural test case design is evolutionary testing. Evolutionary testing searches test data that fulfil a given structural test criteria by means of evolutionary computation. In this work, an evolutionary test environment has been developed that performs fully automatic test data generation for most structural test methods. The introduction of an approximation level for fitness evaluation of generated test data and the definition of an efficient test strategy for processing test goals, increases the performance of evolutionary testing considerably.},
  comment  = {TODO Originales paper über Approach Level.},
  file     = {:papers/evolutionarytest-structural-testing-2.pdf:PDF},
  journal  = {Information and Software Technology},
  keywords = {Test automation, Structural test, Evolutionary test, Evolutionary computation},
  year     = {2001},
}

@Article{Harman2010a,
  author  = {Harman, Mark and McMinn, Phil},
  title   = {A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search},
  doi     = {10.1109/TSE.2009.71},
  number  = {2},
  pages   = {226-247},
  volume  = {36},
  comment = {TODO},
  file    = {:papers/A_Theoretical_and_Empirical_Study_of_Search-Based_Testing_Local_Global_and_Hybrid_Search.pdf:PDF},
  journal = {IEEE Transactions on Software Engineering},
  year    = {2010},
}

@Article{Sampson_1976,
  author    = {Jeffrey R. Sampson},
  title     = {Adaptation in Natural and Artificial Systems (John H. Holland)},
  doi       = {10.1137/1018105},
  number    = {3},
  pages     = {529--530},
  volume    = {18},
  journal   = {{SIAM} Review},
  month     = {jul},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
  year      = {1976},
}

@Book{whitley1989genitor,
  author    = {Whitley, L Darrell and others},
  title     = {The GENITOR algorithm and selection pressure: why rank-based allocation of reproductive trials is best.},
  publisher = {Citeseer},
  comment   = {TODO Erklärt den linearen Selektionsalgorithmus.
Lineare Selektion},
  year      = {1989},
}

@Book{Davis1991,
  author    = {Davis, L.},
  date      = {1991},
  title     = {Handbook of genetic algorithms},
  editor    = {Davis, L.},
  publisher = {Van Nostrand Reinhold, New York},
}

@Article{Ramamoorthy1976,
  author  = {Ramamoorthy, C.V. and Ho, S.-B.F. and Chen, W.T.},
  title   = {On the Automated Generation of Program Test Data},
  doi     = {10.1109/TSE.1976.233835},
  number  = {4},
  pages   = {293-300},
  volume  = {SE-2},
  journal = {IEEE Transactions on Software Engineering},
  year    = {1976},
}

@Article{Lewis1983,
  author    = {Lewis, Harry R.},
  title     = {Michael R. Garey and David S. Johnson. Computers and intractability. A guide to the theory of NP-completeness. W. H. Freeman and Company, San Francisco1979, x 338 pp.},
  doi       = {10.2307/2273574},
  number    = {2},
  pages     = {498–500},
  volume    = {48},
  journal   = {Journal of Symbolic Logic},
  publisher = {Cambridge University Press},
  year      = {1983},
}

@InBook{Tracey2002,
  author    = {Tracey, Nigel and Clark, John and McDermid, John and Mander, Keith},
  booktitle = {Systems Engineering for Business Process Change: New Directions: Collected Papers from the EPSRC Research Programme},
  title     = {A Search-Based Automated Test-Data Generation Framework for Safety-Critical Systems},
  doi       = {10.1007/978-1-4471-0135-2_12},
  editor    = {Henderson, Peter},
  isbn      = {978-1-4471-0135-2},
  pages     = {174--213},
  publisher = {Springer London},
  url       = {https://doi.org/10.1007/978-1-4471-0135-2_12},
  abstract  = {This paper presents the results of a three year research program to develop an automated test-data generation framework to support the testing of safety-critical software systems. The generality of the framework comes from the exploitation of domain independent search techniques, allowing new test criteria to be addressed by constructing functions that quantify the suitability of test-data against the test-criteria. The paper presents four applications of the framework --- specification falsification testing, structural testing, exception condition testing and worst-case execution time testing. The results of three industrial scale case-studies are also presented to show that the framework offers useful support in the development safety-critical software systems.},
  address   = {London},
  comment   = {TODO Branch Distance auch für UNDs und ODERs},
  year      = {2002},
}

@InProceedings{Shamshiri2015a,
  author    = {Shamshiri, Sina and Rojas, Jos\'{e} Miguel and Fraser, Gordon and McMinn, Phil},
  booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
  title     = {Random or Genetic Algorithm Search for Object-Oriented Test Suite Generation?},
  doi       = {10.1145/2739480.2754696},
  isbn      = {9781450334723},
  location  = {Madrid, Spain},
  pages     = {1367–1374},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '15},
  url       = {https://doi.org/10.1145/2739480.2754696},
  abstract  = {Achieving high structural coverage is an important aim in software testing. Several
search-based techniques have proved successful at automatically generating tests that
achieve high coverage. However, despite the well- established arguments behind using
evolutionary search algorithms (e.g., genetic algorithms) in preference to random
search, it remains an open question whether the benefits can actually be observed
in practice when generating unit test suites for object-oriented classes. In this
paper, we report an empirical study on the effects of using a genetic algorithm (GA)
to generate test suites over generating test suites incrementally with random search,
by applying the EvoSuite unit test suite generator to 1,000 classes randomly selected
from the SF110 corpus of open source projects. Surprisingly, the results show little
difference between the coverage achieved by test suites generated with evolutionary
search compared to those generated using random search. A detailed analysis reveals
that the genetic algorithm covers more branches of the type where standard fitness
functions provide guidance. In practice, however, we observed that the vast majority
of branches in the analyzed projects provide no such guidance.},
  address   = {New York, NY, USA},
  comment   = {TODO Random Search kann manchmal sogar effektiver sein, als genetische Algorithmen},
  keywords  = {automated test generation, search based software engineering, genetic algorithms, search based testing, random testing, object oriented unit testing},
  numpages  = {8},
  year      = {2015},
}

@InProceedings{Rojas2015,
  author    = {Rojas, Jos{\'e} Miguel and Campos, Jos{\'e} and Vivanti, Mattia and Fraser, Gordon and Arcuri, Andrea},
  booktitle = {Search-Based Software Engineering},
  title     = {Combining Multiple Coverage Criteria in Search-Based Unit Test Generation},
  editor    = {Barros, M{\'a}rcio and Labiche, Yvan},
  isbn      = {978-3-319-22183-0},
  pages     = {93--108},
  publisher = {Springer International Publishing},
  abstract  = {Automated test generation techniques typically aim at maximising coverage of well-established structural criteria such as statement or branch coverage. In practice, generating tests only for one specific criterion may not be sufficient when testing object oriented classes, as standard structural coverage criteria do not fully capture the properties developers may desire of their unit test suites. For example, covering a large number of statements could be easily achieved by just calling the main method of a class; yet, a good unit test suite would consist of smaller unit tests invoking individual methods, and checking return values and states with test assertions. There are several different properties that test suites should exhibit, and a search-based test generator could easily be extended with additional fitness functions to capture these properties.},
  address   = {Cham},
  comment   = {TODO Mehrere Coverage Kriterien in einer linearen Kombination},
  file      = {:papers/ssbse15_multi.pdf:PDF},
  year      = {2015},
}

@Article{Rojas2017,
  author    = {Rojas, Jos{\'e} Miguel and Vivanti, Mattia and Arcuri, Andrea and Fraser, Gordon},
  title     = {A detailed investigation of the effectiveness of whole test suite generation},
  number    = {2},
  pages     = {852--893},
  volume    = {22},
  comment   = {TODO Whole test suite generation},
  journal   = {Empirical Software Engineering},
  publisher = {Springer},
  year      = {2017},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:a72186:1\;2\;1\;\;\;\;;
1 StaticGroup:State of the Art Tools\;0\;1\;0x0000ffff\;\;\;;
}
